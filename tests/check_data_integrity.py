import torch
from pathlib import Path
from tqdm import tqdm
import argparse
import logging

# --- é…ç½®æ—¥å¿—è®°å½• ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def check_data(processed_dir: str, max_files: int):
    """
    æ‰«æé¢„å¤„ç†å¥½çš„ .pt æ–‡ä»¶ï¼Œæ£€æŸ¥ attention_mask çš„å®Œæ•´æ€§ï¼ŒéªŒè¯æ•°æ®è´¨é‡ã€‚
    """
    processed_path = Path(processed_dir)
    pt_files = sorted(list(processed_path.glob("*.pt")))

    if not pt_files:
        logging.error(f"åœ¨ '{processed_dir}' ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½• .pt æ–‡ä»¶ã€‚")
        logging.error("è¯·ç¡®è®¤é¢„å¤„ç†è„šæœ¬æ˜¯å¦å·²æˆåŠŸè¿è¡Œå¹¶ç”Ÿæˆäº†è¾“å‡ºã€‚")
        return

    files_to_check = pt_files
    if max_files > 0:
        if len(pt_files) > max_files:
            files_to_check = pt_files[:max_files]
            logging.info(f"ğŸ” å‘ç° {len(pt_files)} ä¸ªæ–‡ä»¶ï¼Œå°†æŠ½æ ·æ£€æŸ¥å‰ {len(files_to_check)} ä¸ª...")
        else:
            logging.info(f"ğŸ” å‘ç°å¹¶æ£€æŸ¥å…¨éƒ¨ {len(pt_files)} ä¸ªæ–‡ä»¶...")
    else:
        logging.info(f"ğŸ” å‘ç° {len(pt_files)} ä¸ªæ–‡ä»¶ï¼Œå°†æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶...")

    total_samples = 0
    empty_samples = 0
    non_empty_peak_counts = []

    for pt_file in tqdm(files_to_check, desc="æ‰«ææ–‡ä»¶"):
        try:
            # æ·»åŠ  weights_only=False ä»¥å…¼å®¹æ—§ç‰ˆtorchå¹¶æ¶ˆé™¤è­¦å‘Šï¼Œä½†åœ¨å®é™…ç”Ÿäº§ä¸­éœ€è°¨æ…
            samples = torch.load(pt_file, weights_only=False)
            for sample in samples:
                total_samples += 1
                attention_mask = sample.get('attention_mask')

                if attention_mask is None or not isinstance(attention_mask, torch.Tensor):
                    empty_samples += 1
                    continue

                num_real_peaks = attention_mask.sum().item()
                if num_real_peaks == 0:
                    empty_samples += 1
                else:
                    non_empty_peak_counts.append(num_real_peaks)

        except Exception as e:
            logging.error(f"\nğŸš¨ åŠ è½½æˆ–å¤„ç† {pt_file} æ—¶å‡ºé”™: {e}", exc_info=True)
            continue
    
    print("\n" + "="*60)
    print("--- ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æŠ¥å‘Š ---")
    print("="*60)

    if total_samples == 0:
        logging.error("æœªèƒ½æˆåŠŸåˆ†æä»»ä½•æ ·æœ¬ï¼Œè¯·æ£€æŸ¥.ptæ–‡ä»¶æ˜¯å¦ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ã€‚")
        return
        
    empty_percentage = (empty_samples / total_samples) * 100
    
    print(f"æ€»å…±æ‰«ææ–‡ä»¶æ•°: {len(files_to_check)}")
    print(f"æ€»å…±åˆ†ææ ·æœ¬æ•°: {total_samples}")
    print(f"ä¸åŒ…å«ä»»ä½•çœŸå®å³°çš„æ ·æœ¬æ•° (ç©ºæ ·æœ¬): {empty_samples}")
    print(f"ç©ºæ ·æœ¬æ¯”ä¾‹: {empty_percentage:.2f}%")
    
    if non_empty_peak_counts:
        avg_peaks = sum(non_empty_peak_counts) / len(non_empty_peak_counts)
        min_peaks = min(non_empty_peak_counts)
        max_peaks = max(non_empty_peak_counts)
        print("\n--- å¯¹äºéç©ºæ ·æœ¬çš„ç»Ÿè®¡ ---")
        print(f"æˆåŠŸæå–çš„éç©ºæ ·æœ¬æ•°é‡: {len(non_empty_peak_counts)}")
        print(f"æ¯ä¸ªéç©ºæ ·æœ¬çš„å¹³å‡å³°æ•°: {avg_peaks:.2f}")
        print(f"éç©ºæ ·æœ¬çš„æœ€å°/æœ€å¤§å³°æ•°: {min_peaks} / {max_peaks}")
    else:
        print("\nåœ¨æ‰«æçš„æ–‡ä»¶ä¸­æœªèƒ½æ‰¾åˆ°ä»»ä½•åŒ…å«çœŸå®å³°çš„æ ·æœ¬ã€‚")
        
    print("\n" + "="*60)
    print("--- ğŸ’¡ ç»“è®º ---")
    print("="*60)
    if empty_percentage == 100.0:
        print("â—ï¸ [å¤±è´¥] æ£€æŸ¥å‘ç°æ‰€æœ‰æ ·æœ¬å‡ä¸ºç©ºï¼Œä¸ä¸Šæ¬¡é”™è¯¯æ—¶çš„æƒ…å†µç›¸åŒã€‚")
        print("   'loss=0' çš„é—®é¢˜å‡ ä¹è‚¯å®šä¼šå†æ¬¡å‡ºç°ã€‚")
        print("   ğŸ‘‰ è¯·å†æ¬¡å®¡æŸ¥ 'src/data/preprocess.py' çš„æ•°æ®æå–é€»è¾‘ã€‚")
    elif empty_percentage > 5.0:
        print("âš ï¸ [è­¦å‘Š] å‘ç°äº†è¾ƒé«˜æ¯”ä¾‹çš„ç©ºæ ·æœ¬ (>5%)ã€‚")
        print("   è¿™å¯èƒ½æ˜¯æ•°æ®é›†æœ¬èº«çš„ç‰¹æ€§ï¼Œä½†ä¹Ÿå€¼å¾—å…³æ³¨ã€‚è®­ç»ƒå¯èƒ½ä»ä¼šæˆåŠŸï¼Œä½†æ•°æ®æœ‰æ•ˆç‡ä¸é«˜ã€‚")
    else:
        print("âœ… [æˆåŠŸ] æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ï¼ç©ºæ ·æœ¬æ¯”ä¾‹å¾ˆä½ã€‚")
        print("   è¿™è¡¨æ˜ 'preprocess.py' çš„ä¿®å¤æ˜¯æˆåŠŸçš„ï¼Œ'loss=0' çš„é—®é¢˜æ ¹æºå·²è§£å†³ã€‚")
        print("   æ‚¨å¯ä»¥å……æ»¡ä¿¡å¿ƒåœ°è¿›è¡Œä¸‹ä¸€æ­¥çš„è®­ç»ƒã€‚")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ£€æŸ¥é¢„å¤„ç†å .pt æ–‡ä»¶çš„å®Œæ•´æ€§å’Œè´¨é‡ã€‚")
    parser.add_argument(
        "--dir", 
        type=str, 
        default="data/processed",
        help="åŒ…å«é¢„å¤„ç†å¥½çš„ .pt æ–‡ä»¶çš„ç›®å½•ã€‚"
    )
    parser.add_argument(
        "--max_files",
        type=int,
        default=10, # ç¨å¾®å¢åŠ é»˜è®¤æ£€æŸ¥æ–‡ä»¶æ•°ä»¥æé«˜æ ·æœ¬è¦†ç›–ç‡
        help="æ£€æŸ¥çš„æœ€å¤§æ–‡ä»¶æ•°é‡ã€‚è®¾ç½®ä¸º 0 åˆ™æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶ã€‚"
    )
    args = parser.parse_args()
    
    check_data(args.dir, args.max_files)
