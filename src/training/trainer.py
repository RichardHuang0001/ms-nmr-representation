# <-- [æ ¸å¿ƒ] å°è£…è®­ç»ƒã€éªŒè¯å¾ªçŽ¯å’ŒæŒ‡æ ‡è®¡ç®—
import torch
import torch.nn.functional as F
from tqdm import tqdm
import wandb
import logging
from pathlib import Path

class Trainer:
    """å°è£…è®­ç»ƒå’Œè¯„ä¼°é€»è¾‘çš„è®­ç»ƒå™¨ç±»ã€‚"""
    def __init__(self, model, optimizer, train_loader, val_loader, config):
        self.model = model
        self.optimizer = optimizer
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = torch.device(config.training.device if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)

        # åˆå§‹åŒ–W&B
        wandb.init(project=config.wandb.project_name, name=config.wandb.run_name, config=config)
        wandb.watch(self.model, log_freq=100)

    def _calculate_loss(self, predictions, labels):
        """è®¡ç®—æ··åˆæŸå¤±å‡½æ•°ã€‚"""
        # æ‰¾åˆ°è¢«maskçš„ä½ç½® (labelsä¸­ä¸ä¸º-100çš„åœ°æ–¹)
        active_loss = labels != -100
        active_preds = predictions[active_loss]
        active_labels = labels[active_loss]

        if active_preds.shape[0] == 0:
            return torch.tensor(0.0, device=self.device, requires_grad=True)

        # ä»Žé…ç½®ä¸­èŽ·å–ç‰¹å¾åˆ‡ç‰‡ä¿¡æ¯
        s_mod, e_mod = self.config.feature_slices.modality
        s_num, e_num = self.config.feature_slices.numerical
        s_mult, e_mult = self.config.feature_slices.multiplicity

        # æ•°å€¼éƒ¨åˆ†æŸå¤± (MSE)
        loss_mse = F.mse_loss(active_preds[:, s_num:e_num], active_labels[:, s_num:e_num])

        # ç±»åˆ«éƒ¨åˆ†æŸå¤± (CrossEntropy)
        loss_ce_modality = F.cross_entropy(active_preds[:, s_mod:e_mod], torch.argmax(active_labels[:, s_mod:e_mod], dim=-1))
        loss_ce_mult = F.cross_entropy(active_preds[:, s_mult:e_mult], torch.argmax(active_labels[:, s_mult:e_mult], dim=-1))

        # åŠ æƒæ±‚å’Œ (å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´æƒé‡)
        total_loss = loss_mse + loss_ce_modality + loss_ce_mult
        return total_loss

    def _run_epoch(self, dataloader, is_training=True):
        """è¿è¡Œä¸€ä¸ªepochçš„è®­ç»ƒæˆ–éªŒè¯ã€‚"""
        self.model.train(is_training)
        total_loss = 0.0
        
        progress_bar = tqdm(dataloader, desc=f"{'Train' if is_training else 'Eval'}")
        for batch in progress_bar:
            masked_inputs, masks, labels = [b.to(self.device) for b in batch]

            if is_training:
                self.optimizer.zero_grad()
            
            with torch.set_grad_enabled(is_training):
                predictions = self.model(masked_inputs, masks)
                loss = self._calculate_loss(predictions, labels)

            if is_training:
                loss.backward()
                self.optimizer.step()
            
            total_loss += loss.item()
            progress_bar.set_postfix(loss=loss.item())

        return total_loss / len(dataloader)

    def _save_checkpoint(self, epoch, val_loss, is_best):
        """ä¿å­˜æ¨¡åž‹æ£€æŸ¥ç‚¹ã€‚"""
        if not is_best:
            return

        checkpoint_dir = Path(self.config.training.checkpoint_dir)
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        checkpoint_path = checkpoint_dir / "best_model.pt"
        
        torch.save({
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'val_loss': val_loss,
        }, checkpoint_path)
        logging.info(f"ðŸš€ æ–°çš„æœ€ä½³æ¨¡åž‹å·²ä¿å­˜ (Epoch {epoch+1}, Val Loss: {val_loss:.4f}) è‡³: {checkpoint_path}")

    def train(self):
        """å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚"""
        best_val_loss = float('inf')
        for epoch in range(self.config.training.epochs):
            train_loss = self._run_epoch(self.train_loader, is_training=True)
            val_loss = self._run_epoch(self.val_loader, is_training=False)
            
            logging.info(f"Epoch {epoch+1}/{self.config.training.epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
            wandb.log({"epoch": epoch, "train_loss": train_loss, "val_loss": val_loss})

            # ä»…åœ¨éªŒè¯æŸå¤±æ”¹å–„æ—¶ä¿å­˜æœ€ä½³æ¨¡åž‹
            is_best = val_loss < best_val_loss
            if is_best:
                best_val_loss = val_loss
            self._save_checkpoint(epoch, val_loss, is_best)