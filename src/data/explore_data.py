#!/usr/bin/env python3
"""
æ•°æ®å—…æ¢å·¥å…· (ä¿®æ”¹ç‰ˆ)
ç”¨äºç²¾ç¡®æ¢æŸ¥ç‰¹å®š Parquet æ–‡ä»¶çš„æ•°æ®ç»“æ„å’Œå†…å®¹ï¼Œä»¥è¯Šæ–­é¢„å¤„ç†é—®é¢˜ã€‚
"""

import pandas as pd
import argparse
from pathlib import Path

def print_section(title, char="="):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print(f"\n{char * 80}")
    print(f" {title}")
    print(f"{char * 80}")

def sniff_parquet_file(file_path: Path, ms_col_name: str):
    """
    å—…æ¢å•ä¸ª Parquet æ–‡ä»¶ï¼Œæ‰“å°å…¶ schema å’Œç¬¬ä¸€ä¸ªæ ·æœ¬çš„å…³é”®åˆ—å†…å®¹ã€‚
    """
    print_section(f"ğŸ•µï¸  å¼€å§‹å—…æ¢æ–‡ä»¶: {file_path.name}")

    if not file_path.exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ -> {file_path}")
        return

    try:
        df = pd.read_parquet(file_path)
        print(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸã€‚")
        print(f"   - æ•°æ®å½¢çŠ¶: {df.shape[0]} ä¸ªæ ·æœ¬, {df.shape[1]} ä¸ªç‰¹å¾")

        # 1. æ‰“å°æ‰€æœ‰åˆ—å
        print("\n--- ğŸ“‹ å¯ç”¨åˆ—å (Schema) ---")
        for i, col in enumerate(df.columns, 1):
            print(f"  {i:2d}. {col}")

        # 2. è¯¦ç»†æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬ (sample_idx=0) çš„å…³é”®åˆ—
        print("\n--- ğŸ”¬ ç¬¬ä¸€ä¸ªæ ·æœ¬ (ç´¢å¼•0) çš„å…³é”®åˆ—å†…å®¹æ£€æŸ¥ ---")
        if df.empty:
            print("   - æ–‡ä»¶ä¸ºç©ºï¼Œæ²¡æœ‰æ ·æœ¬å¯ä¾›æ£€æŸ¥ã€‚")
            return
            
        sample = df.iloc[0]

        # å…³é”®åˆ—åˆ—è¡¨
        key_columns = ['h_nmr_peaks', 'c_nmr_peaks', ms_col_name]
        
        for col in key_columns:
            print(f"\n   --- åˆ—: '{col}' ---")
            if col in df.columns:
                data = sample[col]
                print(f"   - (L1) æ•°æ®ç±»å‹: {type(data)}")

                # å¯¹MSåˆ—è¿›è¡Œæ·±åº¦å—…æ¢
                if col == ms_col_name and hasattr(data, '__len__') and len(data) > 0:
                    first_element = data[0]
                    print(f"   - (L2) ç¬¬ä¸€ä¸ªå…ƒç´ çš„æ•°æ®ç±»å‹: {type(first_element)}")
                    
                    if hasattr(first_element, '__len__'):
                        print(f"   - (L3) ç¬¬ä¸€ä¸ªå…ƒç´ çš„é•¿åº¦: {len(first_element)}")
                        print(f"   - (L3) ç¬¬ä¸€ä¸ªå…ƒç´ çš„å†…å®¹: {first_element}")

                print(f"   - æ•°æ®å†…å®¹:")
                # ä¸ºäº†æ›´æ¸…æ™°çš„æ˜¾ç¤ºï¼Œæˆ‘ä»¬å¯¹å†…å®¹è¿›è¡Œæ ¼å¼åŒ–
                if hasattr(data, '__len__') and len(data) > 5:
                    print(f"     (åˆ—è¡¨é•¿åº¦ä¸º {len(data)}, ä»…æ˜¾ç¤ºå‰5ä¸ªå…ƒç´ )")
                    print(f"     {data[:5]}")
                else:
                    print(f"     {data}")
            else:
                print(f"   - â—ï¸ è­¦å‘Š: åœ¨æ–‡ä»¶ä¸­æœªæ‰¾åˆ°è¯¥åˆ—ã€‚")

    except Exception as e:
        print(f"\nâŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Parquet æ–‡ä»¶æ•°æ®å—…æ¢å·¥å…·ã€‚")
    parser.add_argument(
        'filenames', 
        nargs='+', 
        help="è¦å—…æ¢çš„ä¸€ä¸ªæˆ–å¤šä¸ª Parquet æ–‡ä»¶å (ä¾‹å¦‚: aligned_chunk_0.parquet)"
    )
    parser.add_argument(
        '--base_dir', 
        type=str, 
        default="data/raw/nips_2024_dataset/multimodal_spectroscopic_dataset",
        help="å­˜æ”¾ Parquet æ–‡ä»¶çš„åŸºç¡€ç›®å½•ã€‚"
    )
    parser.add_argument(
        '--ms_col', 
        type=str, 
        default='msms_cfmid_positive_20ev', 
        help="è¦æ£€æŸ¥çš„è´¨è°±åˆ—åã€‚"
    )
    args = parser.parse_args()

    for filename in args.filenames:
        file_path = Path(args.base_dir) / filename
        sniff_parquet_file(file_path, args.ms_col)

if __name__ == "__main__":
    main()